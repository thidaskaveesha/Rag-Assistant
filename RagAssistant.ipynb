{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FQPP1q7tBjQQ",
        "outputId": "8abc6627-1293-435f-d502-8c2e6edd0194"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install langchain chromadb sentence-transformers\n",
        "!pip install langchain-community\n",
        "!pip install PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qPbM5HP9CsK-",
        "outputId": "4d6fed69-692b-4178-b718-514656eea8b5"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "# Load a pre-trained embedding model\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dP5d-MgYCt3m"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "# Load documents from files\n",
        "def load_documents_from_files(file_paths):\n",
        "    docs = []\n",
        "    for file_path in file_paths:\n",
        "        if file_path.endswith(\".txt\"):\n",
        "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                docs.append(f.read())\n",
        "        elif file_path.endswith(\".pdf\"):\n",
        "            reader = PdfReader(file_path)\n",
        "            text = \"\"\n",
        "            for page in reader.pages:\n",
        "                text += page.extract_text()\n",
        "            docs.append(text)\n",
        "        else:\n",
        "            print(f\"Unsupported file type: {file_path}\")\n",
        "    return docs\n",
        "\n",
        "# Example file paths (replace with your actual files)\n",
        "file_paths = [\"/content/test.txt\", \"/content/ASSIGNMENT 02.pdf\"]\n",
        "docs = load_documents_from_files(file_paths)\n",
        "\n",
        "# Split documents into smaller chunks for better indexing\n",
        "splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
        "chunks = splitter.create_documents(docs)\n",
        "\n",
        "# Set up ChromaDB\n",
        "vectorstore = Chroma.from_documents(documents=chunks, embedding=embedding_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEVghDPbCxBW",
        "outputId": "3851d4f0-184e-4b51-905f-c657fd7eabaa"
      },
      "outputs": [],
      "source": [
        "query = \"What services does Verizon offer?\"\n",
        "\n",
        "# Perform a similarity search\n",
        "results = vectorstore.similarity_search(query, k=5)\n",
        "\n",
        "# Retrieve the context\n",
        "context = [result.page_content for result in results]\n",
        "print(\"Retrieved Context:\", context)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FbsB39VCAp4F",
        "outputId": "70768f24-3056-46cc-96ee-8a2edf3d8796"
      },
      "outputs": [],
      "source": [
        "!pip install llama-cpp-python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "GVkDhKQeFI9-"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import LlamaCpp\n",
        "\n",
        "# Path to your Llama model\n",
        "llama_model_path = \"./llama-7b.ggmlv3.q4_0.bin\"\n",
        "\n",
        "# Load the Llama model\n",
        "llm = LlamaCpp(model_path=llama_model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAZ84VN-FNa1"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# Create a retriever\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "# Create the RAG pipeline with Llama\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
        "\n",
        "# Ask a question\n",
        "query = \"What services does Verizon offer?\"\n",
        "response = qa_chain.run(query)\n",
        "print(\"Response:\", response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
